{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Droplet Generation System. Hydraulic part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piston Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./img/drop_gen.png)\n",
    "![img](./img/calc_scheme.png)\n",
    "\n",
    "Piston moves by the hydraulic and friction forces action:\n",
    "$$\n",
    "    m_p\\ddot{x_p} = m_pg + F_h - F_{fr},\n",
    "$$\n",
    "### Hydraulic force $F_h$:\n",
    "$$\n",
    "    F_h = p_h A_h - p_t A_t,\n",
    "$$\n",
    "where hydraulic container pressure, according to the Darcy-Weisbach equation and relationship of the lateral surface area of the throttle \"cylinder\" to the position of the spool (**action**) $A_{th}(t) = \\pi D_{th} x_{th}(t)$:\n",
    "$$\n",
    "    p_h = p_l - \\frac{\\zeta_{th}\\rho_h D_h^4}{32D_{th}^2}\\left(\\frac{\\dot{x_p}}{x_{th}}\\right)^2\n",
    "$$\n",
    "test container pressure (according to the Darcy-Weisbach equation):\n",
    "$$\n",
    "    p_t = p_{atm} + \\frac{\\zeta_{exit}\\rho_t D_t^4}{2D_{exit}^4}\\dot{x_p}^2\n",
    "$$\n",
    "\n",
    "Hydraulic/Test container area:\n",
    "$$\n",
    "    A_{h,t}=\\frac{\\pi D_{h,t}^2}{4}\n",
    "$$\n",
    "\n",
    "$p_l$ - pressure of the hydraulic liquid before throttling;\n",
    "$p_{atm}$ - ambient environment (atmosphere) pressure;\n",
    "$\\zeta_{th}, \\zeta_{exit}$ - hydraulic loss coefficients at throttle and at syringe exit respectively;\n",
    "$\\rho_h, \\rho_t$ - densities of the hydraulic and test containers liquids\n",
    "\n",
    "### Friction $F_{fr}$\n",
    "Friction can be considered both by a stribeck curve or mechanical efficiency.\n",
    "Let us use a mechanical efficiency approach:\n",
    "\n",
    "![img](img/mechanical_efficiency.png)\n",
    "\n",
    "$$\n",
    "    F_{fr} = \\max{(F_C, (1-\\eta)F_h)},\n",
    "$$\n",
    "\n",
    "where $\\eta$ - mechanical efficiency;\n",
    "Coulomb friction force:\n",
    "$$\n",
    "    F_C = p_C\\cdot\\max{(A_h, A_t)}\n",
    "$$\n",
    "$p_C$ - pressure difference, which is necessary to overcome the dry friction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State dynamics function\n",
    "\n",
    "Movement starts when acting force larger than friction force.\n",
    "\n",
    "Let us use $x_{\\th}, x_{p}, v_{p}$ in $\\mu m$. Other values are in SI.\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        &   \\dot{x_p} = v_p,\n",
    "        \\\\\n",
    "        &   \\dot{v_p} = \\begin{cases} g + \\frac{1}{m_p}[F_h(x_p, v_p, x_{th}) + F_{fr}(v_p, F_h)], \\text{ if } [|v_p| > 0] \\text{ or } [|F_h + m_pg| > |F_{fr}|]\\\\\n",
    "                        0, \\text{ otherwise }\\end{cases}\n",
    "    \\end{aligned}\n",
    "    \\qquad x_{th} \\in [0, x_{th}^{max}],\n",
    "$$\n",
    "\n",
    "where:\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        & F_h(x_p, v_p, x_{th}) = A_h p_h(x_p, v_p, x_{th}) - A_t p_t(x_p, v_p) \\\\\n",
    "        \n",
    "        &\\qquad \\text {where: } \\\\\n",
    "\n",
    "        &\\qquad p_h(x_p, v_p, x_{th}) = \\begin{cases}\n",
    "            \\max{\\left(\\left[p_l - \\frac{v_p|v_p|}{x_{th}^2}\\frac{\\zeta_{th}\\rho_h D_h^4}{32D_{th}^2} \\right], p_{sv} \\right)}, \\text{ if } [x_{th} > 0] \\\\\n",
    "\n",
    "            \\max{\\left(\\left[p_h\\vert_{x_{th}>0}+(\\frac{x_p\\vert_{x_{th}>0}}{x_p}-1)\\frac{1}{\\beta_{V_h}}\\right], p_{sv}\\right)}, \\text{ otherwise } \\\\\n",
    "        \\end{cases} \\\\\n",
    "        &\\qquad p_t(x_p, v_p) = p_{atm} + sign(x_p - x_{p0})\\cdot \\min{\\left(\\frac{4\\sigma_t}{D_{exit}}, \\left|\\frac{x_p - x_{p0}}{x_p}\\right| \\frac{1}{\\beta_{V_t}} \\right)} + v_p|v_p|\\frac{\\zeta_{exit} \\rho_t D_t^4}{2D_{exit}^4 \\cdot 10^{12}} \\\\\n",
    "        \n",
    "        & F_{fr}(v_p, F_h) = \\begin{cases} \n",
    "            -sign(v_p)\\cdot \\max{[p_C A_{max}, (1-\\eta) F_h]}, \\text{ if } [|v_p|>0] \\\\\n",
    "            \n",
    "            -sign(F_h + m_pg)\\cdot p_C A_{max}, \\text{ otherwise } \\\\\n",
    "        \\end{cases}\n",
    "    \\end{aligned}\n",
    "$$\n",
    "\n",
    "where $A_{max} = \\max{(A_h, A_t)}$; $p_l > p_{atm}$; $p_{sv}$ - saturated vapor pressure of liquid ($2340~Pa$ for water), $\\beta_V$ - liquid volume compression coefficient ($0.49\\cdot 10^{-9}~Pa^{-1}$ for water); \n",
    "$p_h\\vert_{x_{th}>0},~x_p\\vert_{x_{th}>0}$ - last hydraulic pressure and piston position when $x_{th}$ was more than 0;\n",
    "$\\sigma_t$ - surface tension of the test liquid\n",
    "\n",
    "The starting possition is:\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        & x_{p0} = x_p(0) = 10^{3} [\\mu m] \\\\\n",
    "        & v_p(0) = 0 [\\mu m/s]\\\\\n",
    "    \\end{aligned}\n",
    "$$\n",
    "\n",
    "**Note**: It is important to add, that the throttle position cannot be changed immediately. \n",
    "Thus, to model the throttle position changing let us add one more state with some constant changing speed:\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        & \\text{while } x_{th} \\neq x^{act}_{th}: \\\\\n",
    "        &\\qquad \\dot{x_{th}} = sign(x^{act}_{th}-x_{th}) \\cdot v^{max}_{th}\\\\\n",
    "    \\end{aligned}\n",
    "$$\n",
    "\n",
    "## Observations\n",
    "\n",
    "System diameters are in $m$, drop diameter and jet length are in $mm$. Jet speed is in $\\frac{mm}{s}$\n",
    "\n",
    "Let us assume, that we can measure only the length of the test liquid jet $l_{jet}$ and it's velocity $v_{jet}$.\n",
    "\n",
    "According to the existing researches [[1](https://doi.org/10.1007/s00348-003-0629-6), [2](https://doi.org/10.1201/9781420040470)], liquid drop will be formed, if $\\max(l_{jet})>l_{crit}$, where:\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        & \\frac{l_{crit}}{D_{exit}} = 19.5\\cdot 10^3~We^{0.5}(1 + 3Oh)^{0.85} \\\\\n",
    "        & We = \\frac{\\rho_t v_j^2 D_{exit}}{10^{6} \\sigma_t} \\\\\n",
    "        & Oh = \\frac{\\sqrt{We}}{Re} \\\\\n",
    "        & Re = \\frac{\\rho_t v_j D_{exit}}{10^{3} \\mu_t}, \\\\\n",
    "    \\end{aligned}\n",
    "$$\n",
    "\n",
    "where $v_j$ - jet velocity. \n",
    "Empirically it was estimated as $200 \\frac{mm}{s}$.\n",
    "$\\mu_t$ - dynamic viscosity of the test liquid.\n",
    "\n",
    "Droplet diameter [mm] can be estimated as follows:\n",
    "$$\n",
    "    \\frac{D_{d}}{D_{exit}} = 10^3 (1.5\\pi\\sqrt{2 + 3Oh})^{1/3}\n",
    "$$\n",
    "\n",
    "## Running cost function\n",
    "\n",
    "Our formal goal of control:\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "    & l_{jet} \\to l_{crit} & v_{jet} \\to 0\\\\\n",
    "    & \\text{ where: } l_{jet} = 10^{-3}\\frac{D^2_t}{D^2_{exit}} (x_p - x_{p0})\n",
    "    \\end{aligned}\n",
    "\n",
    "$$\n",
    "\n",
    "If $l_{jet} < l_{crit}$ droplet will not detach.\n",
    "If $l_{jet} > l_{crit}$ droplet will detach, but with satellites.\n",
    "\n",
    "Let us achieve this using a stochastic control policy defined by a model $\\rho^{\\theta}(x_{th}|l_{jet})$ with optimizing running cost $r$. $\\rho^{\\theta}$ will be treated as a probability distribution: $x_{th} \\sim \\rho^{\\theta}(\\bullet|l_{jet})$\n",
    "\n",
    "Let us penalize policy by a running cost function:\n",
    "$$\n",
    "    r(l_{jet}) = \\left(1 - \\frac{l_{jet}}{l_{crit}} \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "# Dataset - to create own dataset, DataLoader - for batch generation\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "import random\n",
    "from typing import Tuple, Dict, Optional, Callable, Type, Any\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HydraulicSystem:\n",
    "    \"\"\"System class: hydraulic system. State transition function\"\"\"\n",
    "    \n",
    "    dim_action: int = 1\n",
    "    dim_observation: int = 2\n",
    "    dim_state: int = 3 # 2 states of the piston and 1 state of the real throttle position (changes with constant speed)\n",
    "    \n",
    "    x_th_eps: float = 0.5 # backslash (should be as small as possible)\n",
    "    dx_th_eps: float = 0.1 # used as limit for positions checking\n",
    "    \n",
    "    # Real throttle position limits\n",
    "    # if throttle is opened\n",
    "    x_th_limits = [0, 20] # [µm]\n",
    "    # Policy update time\n",
    "    dt_update_action = 1.0e-4 # s\n",
    "    # Max throttle speed\n",
    "    v_th_max = 0.5*(x_th_limits[1] - x_th_limits[0])/dt_update_action # µm/s\n",
    "    \n",
    "    m_p: float = 20e-3 # kg\n",
    "    p_atm: float = 1e5 # Pa\n",
    "    p_l: float = 1.5e5 + p_atm # Pa\n",
    "    p_h_init: float = p_atm # Pa\n",
    "    g: float = 9.81 # m/s^2\n",
    "    F_g = m_p*g # N\n",
    "    \n",
    "    # Geometry\n",
    "    D_th: float = 200e-6 # Equivalent throttle diameter, m\n",
    "    D_h: float = 20e-3 # m\n",
    "    D_t: float = 20e-3 # m\n",
    "    D_exit: float = 0.33e-3 # m\n",
    "    l_exit: float = 8.5e-3 # m\n",
    "    get_area = lambda D: np.pi*D**2/4 # returns area in [m^2], if input in [m]\n",
    "    A_h = get_area(D_h)\n",
    "    A_t = get_area(D_t)\n",
    "    A_max = max(A_h, A_t)\n",
    "    D_t_exit_2_ratio = D_t**2/D_exit**2\n",
    "    \n",
    "    # Friction params\n",
    "    p_c: float = 10e3 # Pressure difference on the piston to start movement, Pa\n",
    "    eta: float = 0.70 # Mechanical efficiency\n",
    "    F_c = p_c * A_max # Coulomb friction force, N\n",
    "    \n",
    "    # Hydraulic coeficients\n",
    "    zeta_th = 5.0 # might be find empirically (from real equipment). Now it is taken for the valve, see 'Идельчик И. Е. Справочник по гидравлическим сопротивлениям. М., \"Машиностроение\", 1975'\n",
    "    C_D = 0.827 - 0.0085*l_exit/D_exit # see https://doi.org/10.1201/9781420040470\n",
    "    zeta_exit = 1/C_D**2\n",
    "    \n",
    "    # Let us consider water as hydraulic and test liquid\n",
    "    rho_h = 1e3 # kg/m^3\n",
    "    rho_t = 1e3 # kg/m^3\n",
    "    \n",
    "    p_sv_h: float = 2340 # Pa\n",
    "    \n",
    "    beta_v_h: float = 0.49e-9 # Pa^-1\n",
    "    beta_v_t: float = 0.49e-9 # Pa^-1\n",
    "    \n",
    "    sigma_t: float = 73e-3 # N/m\n",
    "    mu_t: float = 1.0e-3 # Pa*s\n",
    "    \n",
    "    # capillar pressure difference to othercome for drop exiting\n",
    "    p_capillar_max = 4*sigma_t/D_exit\n",
    "    \n",
    "    v_j = 200. # jet speed for the stable operation (found experimentaly) [mm/s]\n",
    "    We_j = rho_t*v_j**2*D_exit/(1e6*sigma_t)\n",
    "    Re_j = rho_t*v_j*D_exit/(1e3*mu_t)\n",
    "    Oh_j = np.sqrt(We_j)/Re_j\n",
    "    # Critical jet length\n",
    "    # l_crit = 19.5*np.sqrt(We_j)*(1 + 3*Oh_j)**0.85 * D_exit # see https://doi.org/10.1201/9781420040470\n",
    "    l_crit = 13.4e3*(np.sqrt(We_j) + 3*We_j/Re_j) * D_exit # see https://doi.org/10.1007/s00348-003-0629-6\n",
    "    # Estimated Droplet diameter\n",
    "    D_drop = 1e3*(1.5*np.pi*np.sqrt(2 + 3*Oh_j))**(1/3) * D_exit\n",
    "    \n",
    "    # Coefs of pressure losses\n",
    "    ploss_coef_h = (zeta_th*rho_h*D_h**4)/(32*D_th**2)\n",
    "    ploss_coef_t = (zeta_exit*rho_t*D_t**4)/(2e12*D_exit**4)\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize Hydraulic System\"\"\"\n",
    "        self.reset()\n",
    "    \n",
    "    \n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset system to initial state.\"\"\"\n",
    "        \n",
    "        # p_h|_{x_{th}>0}\n",
    "        self.p_h_last = self.p_h_init\n",
    "        # x_p|_{x_{th}>0}\n",
    "        self.x_p_last = None # define later, if None\n",
    "        # Initial piston position\n",
    "        self.x_p_init = None # define later, if None\n",
    "    \n",
    "        \n",
    "    def get_pressure_hydraulic(self, x_p: float, v_p: float, x_th: float) -> float:\n",
    "        \"\"\" Get pressure in the hydraulic container\n",
    "\n",
    "        Args:\n",
    "            x_p (float): piston position [µm]\n",
    "            v_p (float): piston velocity [µm/s]\n",
    "            x_th (float): throttle position [µm]\n",
    "\n",
    "        Returns:\n",
    "            float: pressure in the hydraulic container [Pa]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define last piston position first time as init piston position\n",
    "        if self.x_p_last is None:\n",
    "            self.x_p_last = x_p\n",
    "        \n",
    "        # Calculate\n",
    "        if x_th > 0:\n",
    "            pressure_hydraulic = self.p_l\n",
    "            # dynamic pressure loss happends only when there is a flow rate\n",
    "            if v_p != 0: \n",
    "                # self.x_th_eps refers to somekind of backslash\n",
    "                pressure_hydraulic -= v_p*(abs(v_p)/\\\n",
    "                    (x_th+self.x_th_eps)**2)*self.ploss_coef_h\n",
    "        else:\n",
    "            assert x_p > 0, 'piston position might be positive'\n",
    "            pressure_hydraulic = self.p_h_last +\\\n",
    "                (self.x_p_last/x_p - 1)/self.beta_v_h\n",
    "        # Pressure cannot be smaller than saturated vapor pressure\n",
    "        pressure_hydraulic = max(self.p_sv_h, pressure_hydraulic)\n",
    "        # Keep for future logging of the low hydraulic pressure.\n",
    "        # if pressure_hydraulic == self.p_sv_h:\n",
    "        #     print('WARNING: low hydraulic pressure')\n",
    "        #     print(f'dx_p = {x_p - self.x_p_init:.3e}')\n",
    "        #     print(f'v_p = {v_p:.3e}')\n",
    "        \n",
    "        # Save piston position and hydraulic pressure if throttle is opened\n",
    "        if x_th > 0:\n",
    "            self.x_p_last = x_p\n",
    "            self.p_h_last = pressure_hydraulic\n",
    "        return pressure_hydraulic\n",
    "    \n",
    "    \n",
    "    def get_pressure_test(self, x_p: float, v_p: float) -> float:\n",
    "        \"\"\" Get pressure in the test container\n",
    "\n",
    "        Args:\n",
    "            x_p (float): piston position [µm]\n",
    "            v_p (float): piston velocity [µm/s]\n",
    "\n",
    "        Returns:\n",
    "            float: pressure in the test container [Pa]\n",
    "        \"\"\"\n",
    "        \n",
    "        assert x_p > 0, 'piston position might be positive'\n",
    "        # Define init piston position, if it is first time\n",
    "        if self.x_p_init is None:\n",
    "            self.x_p_init = x_p\n",
    "        \n",
    "        # Position difference\n",
    "        dx_p = x_p - self.x_p_init\n",
    "        \n",
    "        pressure_capillar = min(\n",
    "            self.p_capillar_max, \n",
    "            abs(dx_p/x_p)/self.beta_v_t\n",
    "        )\n",
    "        \n",
    "        pressure_test = self.p_atm + np.sign(dx_p) * pressure_capillar\n",
    "            \n",
    "        # dynamic pressure loss happends only when there is a flow rate\n",
    "        if v_p != 0:\n",
    "            pressure_test += v_p*abs(v_p) * self.ploss_coef_t\n",
    "        \n",
    "        return pressure_test\n",
    "        \n",
    "    \n",
    "    def get_force_hydraulic(self, x_p: float, v_p: float, x_th: float) -> float:\n",
    "        \"\"\" Get hydraulic force acting on the piston\n",
    "\n",
    "        Args:\n",
    "            x_p (float): piston position [µm]\n",
    "            v_p (float): piston velocity [µm/s]\n",
    "            x_th (float): throttle position [µm]\n",
    "\n",
    "        Returns:\n",
    "            float: hydraulic force [N]\n",
    "        \"\"\"\n",
    "        \n",
    "        p_h = self.get_pressure_hydraulic(x_p, v_p, x_th)\n",
    "        p_t = self.get_pressure_test(x_p, v_p)\n",
    "        \n",
    "        return self.A_h*p_h - self.A_t*p_t\n",
    "        \n",
    "    \n",
    "    def get_force_friction(self, v_p: float, F_h: float) -> float:\n",
    "        \"\"\" Get friction force acting on the piston\n",
    "\n",
    "        Args:\n",
    "            v_p (float): piston velocity [µm/s]\n",
    "            F_h (float): Hydraulic force [N]\n",
    "\n",
    "        Returns:\n",
    "            float: friction force [N]\n",
    "        \"\"\"\n",
    "        \n",
    "        if v_p > 0:\n",
    "            return - np.sign(v_p) * max(self.F_c, (1-self.eta)*F_h)\n",
    "        # If piston does not move\n",
    "        return -np.sign(self.F_g + F_h) * self.F_c\n",
    "    \n",
    "    \n",
    "    def get_acceleration(self, x_p: float, v_p: float, x_th: float) -> float:\n",
    "        \"\"\" Get piston acceleration\n",
    "\n",
    "        Args:\n",
    "            x_p (float): piston position [µm]\n",
    "            v_p (float): piston velocity [µm/s]\n",
    "            x_th (float): throttle position [µm]\n",
    "\n",
    "        Returns:\n",
    "            float: piston acceleration [m/s^2]\n",
    "        \"\"\"\n",
    "        F_h = self.get_force_hydraulic(x_p, v_p, x_th)\n",
    "        F_fr = self.get_force_friction(v_p, F_h)\n",
    "        \n",
    "        if (abs(v_p) > 0) or (abs(F_h + self.F_g) > abs(F_fr)):\n",
    "            return (self.g + 1/self.m_p * (F_h + F_fr))*1e6\n",
    "        return 0 # if piston does not move and acting force lower than friction\n",
    "    \n",
    "    \n",
    "    def compute_dynamics(self, state: np.array, action: np.array) -> np.array:\n",
    "        \"\"\"Calculate right-hand-side (rhs) for ODE solver (or Euler integrator)\n",
    "\n",
    "        Args:\n",
    "            state (np.array): current state\n",
    "            action (np.array): current action\n",
    "\n",
    "        Returns:\n",
    "            np.array: rhs for the ODE solver\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get states\n",
    "        x_p = state[0]\n",
    "        v_p = state[1]\n",
    "        # real throttle position\n",
    "        # If real throttle position out of bounds - end throttle movement and set in bounds\n",
    "        x_th = max(self.x_th_limits[0], state[2])\n",
    "        x_th = min(self.x_th_limits[1], x_th)\n",
    "        \n",
    "        # Get and modify action\n",
    "        x_th_act = max(self.x_th_limits[0], action[0]) # consider negative action as closed throttle\n",
    "        # For expanded actions\n",
    "        x_th_act = min(self.x_th_limits[1], x_th_act)\n",
    "        assert (x_th_act >= self.x_th_limits[0]) and (x_th_act <= self.x_th_limits[1]), 'action out of the bounds'\n",
    "        \n",
    "        # Get Dstates\n",
    "        Dstate = np.zeros(self.dim_state)\n",
    "        # \\dot{x_th}\n",
    "        # if real throttle position is differ from the set one, change it\n",
    "        if abs(x_th_act - x_th) > self.dx_th_eps:\n",
    "            Dstate[2] = np.sign(x_th_act - x_th) * self.v_th_max\n",
    "        else:\n",
    "            x_th = x_th_act # set throttle position exact as what we want to act\n",
    "            Dstate[2] = 0\n",
    "        \n",
    "        # \\dot{x_p}\n",
    "        Dstate[0] = v_p\n",
    "        # \\dot{v_p}\n",
    "        Dstate[1] = self.get_acceleration(x_p, v_p, x_th)\n",
    "        \n",
    "        return Dstate\n",
    "    \n",
    "    \n",
    "    def get_jet_velocity(self, v_p: float) -> float:\n",
    "        \"\"\"Get exit jet velocity\n",
    "\n",
    "        Args:\n",
    "            v_p (float): piston velocity [µm/s]\n",
    "\n",
    "        Returns:\n",
    "            float: exit jet velocity [mm/s]\n",
    "        \"\"\"\n",
    "        return 1e-3 * v_p * self.D_t_exit_2_ratio\n",
    "    \n",
    "    \n",
    "    def get_jet_length(self, x_p: float) -> float:\n",
    "        \"\"\"Get objective (jet length (which necessary to compare with l_crit))\n",
    "\n",
    "        Args:\n",
    "            x_p (float): piston position [µm]\n",
    "\n",
    "        Returns:\n",
    "            float: objective [mm]\n",
    "        \"\"\"\n",
    "        return 1e-3 * (x_p - self.x_p_init) * self.D_t_exit_2_ratio\n",
    "    \n",
    "    \n",
    "    def get_observation(self, state: np.array) -> np.array:\n",
    "        \"\"\"Get observation (relative jet length)\n",
    "\n",
    "        Args:\n",
    "            state (np.array): system state\n",
    "\n",
    "        Returns:\n",
    "            np.array: observation\n",
    "        \"\"\"\n",
    "        x_p = state[0]\n",
    "        v_p = state[1]\n",
    "        \n",
    "        # Define init piston position, if it is first time\n",
    "        if self.x_p_init is None:\n",
    "            self.x_p_init = x_p\n",
    "        \n",
    "        observation = np.zeros(self.dim_observation)\n",
    "        observation[0] = self.get_jet_length(x_p) / self.l_crit\n",
    "        # add relative velocity\n",
    "        observation[1] = self.get_jet_velocity(v_p) / self.l_crit *\\\n",
    "            self.dt_update_action\n",
    "        \n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator\n",
    "\n",
    "Let us implement it with ODE-solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator:\n",
    "    \"\"\"Integrator\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        system: HydraulicSystem,\n",
    "        N_steps: int,\n",
    "        state_init: np.array,\n",
    "        step_size: float = 1e-4, # s\n",
    "        time_scale_first = 1e-6, # 1e-9 , for the first step\n",
    "        time_scale_max = np.inf, # 1e-4, # for the max step in solve_ivp\n",
    "        atol = 1e-7,\n",
    "        rtol = 1e-4,\n",
    "    ):\n",
    "        self.system = system\n",
    "        self.N_steps = N_steps\n",
    "        self.step_size = step_size\n",
    "        \n",
    "        if time_scale_first is None:\n",
    "            self.first_step = None # solve_ivp will choose first time step\n",
    "        else:\n",
    "            # define first step for the solve_ivp\n",
    "            self.first_step = time_scale_first * step_size\n",
    "        self.max_step = time_scale_max*step_size # max_step for the ivp\n",
    "        self.atol = atol\n",
    "        self.rtol = rtol\n",
    "        \n",
    "        self.state_init = np.zeros(system.dim_state)\n",
    "        self.state_init[:-1] = state_init.copy()\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    \n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets the system to initial state\"\"\"\n",
    "        self.current_step_idx = 0\n",
    "        self.state = self.state_init.copy()\n",
    "        self.action = np.zeros(self.system.dim_action)\n",
    "        self.system.reset()\n",
    "    \n",
    "    \n",
    "    def set_action(self, action: np.array) -> None:\n",
    "        \"\"\" Save current action to 'self.action'\n",
    "\n",
    "        Args:\n",
    "            action (np.array): current action\n",
    "        \"\"\"\n",
    "        self.action = action.copy()\n",
    "    \n",
    "    \n",
    "    def system_transition_function(self, state: np.array, action: np.array) -> np.array:\n",
    "        \"\"\" Ger next state by the action\n",
    "\n",
    "        Args:\n",
    "            state (np.array): system state\n",
    "            action (np.array): system action\n",
    "\n",
    "        Returns:\n",
    "            np.array: next state\n",
    "        \"\"\"\n",
    "        def rhs(t: float, y: np.array) -> np.array:\n",
    "            \"\"\" Get rhs (Dstates) for the ode-solver\n",
    "\n",
    "            Args:\n",
    "                t (float): time\n",
    "                y (np.array): state (in scipy notation)\n",
    "\n",
    "            Returns:\n",
    "                np.array: rhs (Dstates) for the ode-solver\n",
    "            \"\"\"\n",
    "            return self.system.compute_dynamics(y, action)\n",
    "        \n",
    "        next_state = solve_ivp(\n",
    "            fun=rhs, \n",
    "            t_span=(0, self.step_size), \n",
    "            y0=state,\n",
    "            first_step=self.first_step,\n",
    "            max_step=self.max_step,\n",
    "            rtol=self.rtol,\n",
    "            atol=self.atol,\n",
    "        ).y.T[-1]\n",
    "        \n",
    "        return next_state\n",
    "    \n",
    "    \n",
    "    def step(self) -> bool:\n",
    "        \"\"\" Do one integration step with step_size\n",
    "\n",
    "        Returns:\n",
    "            bool: status of simulation. 'True' - simulation continues, 'False' - simulation stopped\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.current_step_idx <= self.N_steps:\n",
    "            self.state = self.system_transition_function(self.state, self.action)\n",
    "            self.current_step_idx += 1\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def get_sim_step_data(self) -> Tuple[int, np.array, np.array]:\n",
    "        \"\"\" Get current step id, observation and action\n",
    "\n",
    "        Returns:\n",
    "            Tuple[int, np.array, np.array]: _description_\n",
    "        \"\"\"\n",
    "        \n",
    "        return (\n",
    "            int(self.current_step_idx),\n",
    "            self.system.get_observation(self.state),\n",
    "            np.copy(self.action)\n",
    "        )\n",
    "    \n",
    "    def get_state_step_data(self) -> np.array:\n",
    "        return self.state.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system = HydraulicSystem()\n",
    "simulator = Simulator(system, N_steps=100, state_init=np.array([1e3, 0]))\n",
    "\n",
    "observations = []\n",
    "actions = []\n",
    "states = []\n",
    "\n",
    "while simulator.step():\n",
    "    (\n",
    "        step_idx,\n",
    "        observation,\n",
    "        action,\n",
    "    ) = simulator.get_sim_step_data()\n",
    "    \n",
    "    state = simulator.get_state_step_data()\n",
    "    \n",
    "    step_idx_max = 20\n",
    "    \n",
    "    if simulator.current_step_idx <= step_idx_max:\n",
    "        new_action = np.array([16.5 * simulator.current_step_idx/step_idx_max])\n",
    "    elif simulator.current_step_idx <= step_idx_max + 10:\n",
    "        new_action = np.array([16.5])\n",
    "    else:\n",
    "        new_action = np.array([-1.])\n",
    "    \n",
    "    new_action = np.round(new_action,1)\n",
    "    \n",
    "    simulator.set_action(new_action)\n",
    "    observations.append(observation)\n",
    "    actions.append(action)\n",
    "    states.append(state)\n",
    "\n",
    "states_arr = np.array(states)\n",
    "\n",
    "fig, (ax_length, ax_velocity, ax_action) = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\n",
    "ax_length.plot(np.array(observations)[:,0])\n",
    "ax_length.grid()\n",
    "ax_length.set_title('Relative jet length')\n",
    "\n",
    "ax_velocity.plot(np.array(observations)[:,1])\n",
    "ax_velocity.grid()\n",
    "ax_velocity.set_title('Relative jet velocity')\n",
    "\n",
    "ax_action.plot(np.array(actions)[:, 0], label='action')\n",
    "ax_action.plot(states_arr[:, 2], label='x_th')\n",
    "ax_action.grid()\n",
    "ax_action.set_title('Throttle position (action)');\n",
    "ax_action.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience replay\n",
    "\n",
    "Let us save all our observations and actions for gradient descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterationBuffer(Dataset):\n",
    "    \"\"\"Buffer for experience replay\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize `IterationBuffer`\"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.next_baselines = None\n",
    "        self.nullify_buffer()\n",
    "\n",
    "\n",
    "    def nullify_buffer(self) -> None:\n",
    "        \"\"\"Clear all buffer data\"\"\"\n",
    "\n",
    "        self.episode_ids = []\n",
    "        self.observations = []\n",
    "        self.actions = []\n",
    "        self.running_objectives = []\n",
    "        self.step_ids = []\n",
    "        self.total_objectives = None\n",
    "        self.baselines = None\n",
    "    \n",
    "      \n",
    "    def add_step_data(\n",
    "        self,\n",
    "        observation: np.array,\n",
    "        action: np.array,\n",
    "        running_objective: float,\n",
    "        step_id: int,\n",
    "        episode_id: int,\n",
    "    ):\n",
    "        \"\"\"Add step data to experience replay\n",
    "\n",
    "        Args:\n",
    "            observation (np.array): current observation\n",
    "            action (np.array): current action\n",
    "            running_objective (float): current running objective\n",
    "            step_id (int): current step\n",
    "            episode_id (int): current episode\n",
    "        \"\"\"\n",
    "        self.observations.append(observation)\n",
    "        self.actions.append(action)\n",
    "        self.running_objectives.append(running_objective)\n",
    "        self.episode_ids.append(int(episode_id))\n",
    "        self.step_ids.append(step_id)\n",
    "        \n",
    "    \n",
    "    def get_N_episodes(self) -> int:\n",
    "        \"\"\"Get number of episodes\n",
    "\n",
    "        Returns:\n",
    "            int: number of episodes\n",
    "        \"\"\"\n",
    "        return len(np.unique(self.episode_ids))\n",
    "    \n",
    "    \n",
    "    def calculate_tail_total_objectives_and_next_baselines(\n",
    "        self,\n",
    "    ) -> Tuple[np.array, float, float]:\n",
    "        \"\"\"Calculate tail total costs and baseline. Applied in 'getitem'\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.array, float, float]: tuple of 3 elements # 2 elements, without gradent_normalization_constant\n",
    "            tail_total_objectives, baseline, gradent_normalization_constant\n",
    "        \"\"\"\n",
    "\n",
    "        unique_episode_ids = np.unique(self.episode_ids)\n",
    "        # We will keep the same episode indexes in pd.Series for a convenient calculation of the tail total objectives\n",
    "        running_objectives_series = pd.Series(\n",
    "            index=self.episode_ids, data=self.running_objectives\n",
    "        )\n",
    "        \n",
    "        # Sum of inverted rows in one episode for all episodes (like summation from the end)\n",
    "        # Then - invert to get tail sums for each element!\n",
    "        tail_total_objectives = pd.concat(\n",
    "            [\n",
    "                running_objectives_series.loc[i][::-1].cumsum()[::-1]\n",
    "                for i in unique_episode_ids\n",
    "            ]\n",
    "        ).values.reshape(-1)\n",
    "\n",
    "        # already gothern tail sums for each episode\n",
    "        # Thus, we need to get an average of tail sums on all episodes for each step \n",
    "        next_baselines = (\n",
    "            pd.Series(index=self.step_ids, data=tail_total_objectives)\n",
    "            .groupby(level=0) # group by indexes\n",
    "            .mean()\n",
    "            .loc[self.step_ids] # expand means on steps of all episodes\n",
    "            .values.reshape(-1)\n",
    "        )\n",
    "\n",
    "        return tail_total_objectives, next_baselines\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Get length of buffer. The method should be overrided due to inheritance from `torch.utils.data.Dataset`\n",
    "\n",
    "        Returns:\n",
    "            int: length of buffer\n",
    "        \"\"\"\n",
    "        return len(self.observations)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.tensor]:\n",
    "        \"\"\"Get item with id `idx`. The method should be overrided due to inheritance from `torch.utils.data.Dataset`\n",
    "\n",
    "        Args:\n",
    "            idx (int): id of dataset item to return\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, torch.tensor]: dataset item, containing catted observation-action, tail total objective and baselines\n",
    "        \"\"\"\n",
    "        \n",
    "        # If total_objectives are not filled out, fill out them and next_baselines\n",
    "        if self.total_objectives is None:\n",
    "            # Take baseline from next_baseline if the latter exists\n",
    "            self.baselines = (\n",
    "                self.next_baselines\n",
    "                if self.next_baselines is not None\n",
    "                else np.zeros(shape=len(self.observations))\n",
    "            )\n",
    "\n",
    "            (\n",
    "                self.total_objectives,\n",
    "                self.next_baselines,\n",
    "            ) = self.calculate_tail_total_objectives_and_next_baselines()\n",
    "\n",
    "        observation = torch.tensor(self.observations[idx])\n",
    "        action = torch.tensor(self.actions[idx])\n",
    "\n",
    "        return {\n",
    "            \"observations_actions\": torch.cat([observation, action]).float(),\n",
    "            \"tail_total_objectives\": torch.tensor(self.total_objectives[idx]).float(),\n",
    "            \"baselines\": torch.tensor(self.baselines[idx]).float(),\n",
    "        }\n",
    "\n",
    "\n",
    "    @property\n",
    "    def data(self) -> pd.DataFrame:\n",
    "        \"\"\"Return current buffer content in pandas.DataFrame\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: current buffer content\n",
    "        \"\"\"\n",
    "\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"episode_id\": self.episode_ids,\n",
    "                \"step_id\": self.step_ids,\n",
    "                \"observation\": self.observations,\n",
    "                \"action\": self.actions,\n",
    "                \"running_objective\": self.running_objectives,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Model for policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The policy model will be taken as:\n",
    "\n",
    "$$\n",
    "    \\rho^{\\theta}(x^{act}_{th}|l_{jet}, v_{jet})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianPDFModel(nn.Module):\n",
    "    \"\"\"Model for REINFORCE algorithm that acts like f(x) + normally distributed noise\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_observation: int,\n",
    "        dim_action: int,\n",
    "        dim_hidden: int,\n",
    "        std: float,\n",
    "        action_bounds: np.array,\n",
    "        scale_factor: float,\n",
    "        leakyrelu_coef=0.2,\n",
    "    ):\n",
    "        \"\"\"Initialize model.\n",
    "\n",
    "        Args:\n",
    "            dim_observation (int): dimensionality of observation\n",
    "            dim_action (int): dimensionality of action\n",
    "            dim_hidden (int): dimensionality of hidden layer of perceptron (dim_hidden = 4 works for our case)\n",
    "            std (float): standard deviation of noise (\\\\sigma)\n",
    "            action_bounds (np.array): action bounds with shape (dim_action, 2). `action_bounds[:, 0]` - minimal actions, `action_bounds[:, 1]` - maximal actions\n",
    "            scale_factor (float): scale factor for last activation (L coefficient) (see details above)\n",
    "            leakyrelu_coef (float): coefficient for leakyrelu\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim_observation = dim_observation\n",
    "        self.dim_action = dim_action\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.leakyrelu_coef = leakyrelu_coef\n",
    "        self.std = std\n",
    "\n",
    "        self.scale_factor = scale_factor\n",
    "        self.register_parameter(\n",
    "            name=\"scale_tril_matrix\",\n",
    "            param=torch.nn.Parameter(\n",
    "                (self.std * torch.eye(self.dim_action)).float(),\n",
    "                requires_grad=False,\n",
    "            ),\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"action_bounds\",\n",
    "            param=torch.nn.Parameter(\n",
    "                torch.tensor(action_bounds).float(),\n",
    "                requires_grad=False,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # HINT\n",
    "        #\n",
    "        # Define your perceptron (or its layers) here\n",
    "        #\n",
    "        # TAs used nn.Sequential(...)\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
    "\n",
    "        self.mu_nn = nn.Sequential(\n",
    "            nn.Linear(self.dim_observation, self.dim_hidden),\n",
    "            nn.LeakyReLU(self.leakyrelu_coef),\n",
    "            nn.Linear(self.dim_hidden, self.dim_hidden),\n",
    "            nn.LeakyReLU(self.leakyrelu_coef),\n",
    "            nn.Linear(self.dim_hidden, self.dim_action),\n",
    "            # nn.Tanh(), # (1-3\\sigma) transformations might be later\n",
    "        )\n",
    "        # init last activation layer\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    def get_unscale_coefs_from_minus_one_one_to_action_bounds(\n",
    "        self,\n",
    "    ) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
    "        \"\"\"Calculate coefficients for linear transformation from [-1, 1] to [U_min, U_max].\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.FloatTensor, torch.FloatTensor]: coefficients\n",
    "        \"\"\"\n",
    "\n",
    "        action_bounds = self.get_parameter(\"action_bounds\")\n",
    "        #-----------------------------------------------------------------------\n",
    "        # HINT\n",
    "        #\n",
    "        # You need to return a tuple of \\\\beta, \\\\lambda\n",
    "        #\n",
    "        # Note that action bounds are denoted above as [U_min, U_max]\n",
    "        #\n",
    "        u_min = self.action_bounds[:,0]\n",
    "        u_max = self.action_bounds[:,1]\n",
    "        \n",
    "        beta_ = (u_min + u_max)/2\n",
    "        lambda_ = (u_max - u_min)/2\n",
    "        \n",
    "        return beta_, lambda_\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "\n",
    "    def unscale_from_minus_one_one_to_action_bounds(\n",
    "        self, x: torch.FloatTensor\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"Linear transformation from [-1, 1] to [U_min, U_max].\n",
    "\n",
    "        Args:\n",
    "            x (torch.FloatTensor): tensor to transform\n",
    "\n",
    "        Returns:\n",
    "            torch.FloatTensor: transformed tensor\n",
    "        \"\"\"\n",
    "\n",
    "        (\n",
    "            unscale_bias,\n",
    "            unscale_multiplier,\n",
    "        ) = self.get_unscale_coefs_from_minus_one_one_to_action_bounds()\n",
    "\n",
    "        return x * unscale_multiplier + unscale_bias\n",
    "\n",
    "    def scale_from_action_bounds_to_minus_one_one(\n",
    "        self, y: torch.FloatTensor\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"Linear transformation from [U_min, U_max] to [-1, 1].\n",
    "\n",
    "        Args:\n",
    "            y (torch.FloatTensor): tensor to transform\n",
    "\n",
    "        Returns:\n",
    "            torch.FloatTensor: transformed tensor\n",
    "        \"\"\"\n",
    "\n",
    "        (\n",
    "            unscale_bias,\n",
    "            unscale_multiplier,\n",
    "        ) = self.get_unscale_coefs_from_minus_one_one_to_action_bounds()\n",
    "\n",
    "        return (y - unscale_bias) / unscale_multiplier\n",
    "\n",
    "    def get_means(self, observations: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Return mean for MultivariateNormal from `observations`\n",
    "\n",
    "        Args:\n",
    "            observations (torch.FloatTensor): observations\n",
    "\n",
    "        Returns:\n",
    "            torch.FloatTensor: means\n",
    "        \"\"\"\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # HINT\n",
    "        #\n",
    "        # You should return here exactly the \\\\mu_theta(observations)\n",
    "        \n",
    "        # First - make forward step with current observations\n",
    "        nn_result = self.mu_nn(observations)\n",
    "        # Then, divide by scale_factor (L) and put into the nn.Tanh()\n",
    "        mu_activation = self.tanh(nn_result/self.scale_factor)\n",
    "        # Then multiply by (1 - 3*std)\n",
    "        ## [WRONG] to multiply by (1 - 3*self.scale_tril_matrix)\n",
    "        return (1 - 3*self.std)*mu_activation\n",
    "        \n",
    "        #-----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    def split_to_observations_actions(\n",
    "        self, observations_actions: torch.FloatTensor\n",
    "    ) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
    "        \"\"\"Split input tensor to tuple of observation(s) and action(s)\n",
    "\n",
    "        Args:\n",
    "            observations_actions (torch.FloatTensor): tensor of catted observations actions to split\n",
    "\n",
    "        Raises:\n",
    "            ValueError: in case if `observations_actions` has dimensinality greater than 2\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.FloatTensor, torch.FloatTensor]: tuple of observation(s) and action(s)\n",
    "        \"\"\"\n",
    "\n",
    "        if len(observations_actions.shape) == 1:\n",
    "            observation, action = (\n",
    "                observations_actions[: self.dim_observation],\n",
    "                observations_actions[self.dim_observation :],\n",
    "            )\n",
    "        elif len(observations_actions.shape) == 2:\n",
    "            observation, action = (\n",
    "                observations_actions[:, : self.dim_observation],\n",
    "                observations_actions[:, self.dim_observation :],\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Input tensor has unexpected dims\")\n",
    "\n",
    "        return observation, action\n",
    "\n",
    "    def get_unscale_mean_and_variance(\n",
    "        self, \n",
    "        observations: torch.FloatTensor,\n",
    "        scale_tril_matrix: torch.nn.parameter.Parameter,\n",
    "    ) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
    "        \"\"\" Get unscaled mean and covariance matrix for the pdf_Normal\n",
    "\n",
    "        Args:\n",
    "            observations (torch.FloatTensor): observations batch\n",
    "            scale_tril_matrix (torch.nn.parameter.Parameter): covariance matrix\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.FloatTensor, torch.FloatTensor]: Unscaled mean and covariance matrix for the pdf_Normal\n",
    "        \"\"\"\n",
    "        # Get means in range [-1, 1]\n",
    "        mu_scaled = self.get_means(observations)\n",
    "\n",
    "        # Return back to the action range [U_min, U_max]\n",
    "        mu_unscaled = self.unscale_from_minus_one_one_to_action_bounds(mu_scaled)\n",
    "        # Get lambda\n",
    "        (\n",
    "            _,\n",
    "            unscale_multiplier,\n",
    "        ) = self.get_unscale_coefs_from_minus_one_one_to_action_bounds()\n",
    "        \n",
    "        # Get unscaled lower-triangular factor of covariance\n",
    "        tril_unscaled = unscale_multiplier * scale_tril_matrix\n",
    "        \n",
    "        return mu_unscaled, tril_unscaled\n",
    "        \n",
    "        \n",
    "\n",
    "    def log_probs(self, batch_of_observations_actions: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Get log pdf from the batch of observations actions\n",
    "\n",
    "        Args:\n",
    "            batch_of_observations_actions (torch.FloatTensor): batch of catted observations and actions\n",
    "\n",
    "        Returns:\n",
    "            torch.FloatTensor: log pdf(action | observation) for the batch of observations and actions\n",
    "        \"\"\"\n",
    "\n",
    "        observations, actions = self.split_to_observations_actions(\n",
    "            batch_of_observations_actions\n",
    "        )\n",
    "\n",
    "        scale_tril_matrix = self.get_parameter(\"scale_tril_matrix\")\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # HINT\n",
    "        # You should calculate pdf_Normal(\\\\lambda \\\\mu_theta(observations) + \\\\beta, \\\\lambda ** 2 \\\\sigma ** 2)(actions)\n",
    "        #\n",
    "        # TAs used not NormalDistribution, but MultivariateNormal\n",
    "        # See here https://pytorch.org/docs/stable/distributions.html#multivariatenormal\n",
    "        \n",
    "        # Get unscaled mean and variance\n",
    "        (\n",
    "            mu_unscaled, \n",
    "            tril_unscaled\n",
    "        ) = self.get_unscale_mean_and_variance(observations, scale_tril_matrix)\n",
    "        \n",
    "        # Get set of pdfs\n",
    "        multi_norm = MultivariateNormal(\n",
    "            loc=mu_unscaled, # \\\\lambda \\\\mu_theta(observations) + \\\\beta\n",
    "            scale_tril=tril_unscaled, # \\\\lambda \\\\sigma\n",
    "        )\n",
    "        # actions = actions.squeeze() # Get one-dim vector\n",
    "        # Calculate log pdf(action | observation)\n",
    "        return multi_norm.log_prob(actions)\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    def sample(self, observation: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Sample action from `MultivariteNormal(lambda * self.get_means(observation) + beta, lambda ** 2 * Diag[self.std] ** 2)`\n",
    "\n",
    "        Args:\n",
    "            observation (torch.FloatTensor): current observation\n",
    "\n",
    "        Returns:\n",
    "            torch.FloatTensor: sampled action\n",
    "        \"\"\"\n",
    "        action_bounds = self.get_parameter(\"action_bounds\")\n",
    "        scale_tril_matrix = self.get_parameter(\"scale_tril_matrix\")\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # HINT\n",
    "        # Sample action from `MultivariteNormal(lambda * self.get_means(observation) + beta, lambda ** 2 * Diag[self.std] ** 2)\n",
    "\n",
    "        # Get unscaled mean and variance\n",
    "        (\n",
    "            mu_unscaled, \n",
    "            tril_unscaled\n",
    "        ) = self.get_unscale_mean_and_variance(observation, scale_tril_matrix)\n",
    "        \n",
    "        # Get set of pdfs\n",
    "        multi_norm = MultivariateNormal(\n",
    "            loc=mu_unscaled, # \\\\lambda \\\\mu_theta(observations) + \\\\beta\n",
    "            scale_tril=tril_unscaled, # \\\\lambda \\\\sigma\n",
    "        )\n",
    "        \n",
    "        sampled_action = multi_norm.rsample()\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        return torch.clamp(\n",
    "            sampled_action, action_bounds[:, 0], action_bounds[:, 1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRSchedulerSwitch:\n",
    "    \"\"\"Callable class that returns True in case ||observation|| <= norm_observation_threshold\"\"\"\n",
    "\n",
    "    def __init__(self, norm_observation_threshold: float) -> None:\n",
    "        \"\"\"Initialize LRSchedulerSwitch.\n",
    "\n",
    "        Args:\n",
    "            norm_observation_threshold (float): threshold for observation norm\n",
    "        \"\"\"\n",
    "        self.norm_observation_threshold = norm_observation_threshold\n",
    "        self.turned_on = False\n",
    "\n",
    "    def __call__(self, observation: np.array) -> bool:\n",
    "        \"\"\"Return True if ||observation|| <= norm_observation_threshold\n",
    "\n",
    "        Args:\n",
    "            observation (np.array): observation\n",
    "\n",
    "        Returns:\n",
    "            bool: ||observation|| <= norm_observation_threshold\n",
    "        \"\"\"\n",
    "\n",
    "        if (\n",
    "            self.turned_on\n",
    "            or np.linalg.norm(observation) <= self.norm_observation_threshold\n",
    "        ):\n",
    "            self.turned_on = True\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    \"\"\"Does gradient step for optimizing model weights\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        opt_method: Type[torch.optim.Optimizer],\n",
    "        opt_options: Dict[str, Any],\n",
    "        lr_scheduler_method: Optional[torch.optim.lr_scheduler.LRScheduler] = None,\n",
    "        lr_scheduler_options: Optional[Dict[str, Any]] = None,\n",
    "        lr_scheduler_switch: Callable[[np.array], bool] = lambda _: True,\n",
    "        shuffle: bool = False,\n",
    "    ):\n",
    "        \"\"\"Initialize Optimizer\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): model which weights we need to optimize\n",
    "            opt_method (Type[torch.optim.Optimizer]): method type for optimization. For instance, `opt_method=torch.optim.SGD`\n",
    "            opt_options (Dict[str, Any]): kwargs dict for opt method\n",
    "            lr_scheduler_method (Optional[torch.optim.lr_scheduler.LRScheduler], optional): method type for LRScheduler. Defaults to None\n",
    "            lr_scheduler_options (Optional[Dict[str, Any]], optional): kwargs for LRScheduler. Defaults to None\n",
    "            lr_scheduler_switch (Callable[[np.array], bool]): callable object for turning on the sheduller. Defaults to lambda _: True\n",
    "            shuffle (bool, optional): whether to shuffle items in dataset. Defaults to True\n",
    "        \"\"\"\n",
    "\n",
    "        self.opt_method = opt_method\n",
    "        self.opt_options = opt_options\n",
    "        self.shuffle = shuffle\n",
    "        self.model = model\n",
    "        self.optimizer = self.opt_method(self.model.parameters(), **self.opt_options)\n",
    "        self.lr_scheduler_method = lr_scheduler_method\n",
    "        self.lr_scheduler_options = lr_scheduler_options\n",
    "        self.lr_scheduler_switch = lr_scheduler_switch\n",
    "        if self.lr_scheduler_method is not None:\n",
    "            self.lr_scheduler = self.lr_scheduler_method(\n",
    "                self.optimizer, **self.lr_scheduler_options\n",
    "            )\n",
    "        else:\n",
    "            self.lr_scheduler = None\n",
    "\n",
    "    def optimize(\n",
    "        self,\n",
    "        objective: Callable[[torch.tensor], torch.tensor],\n",
    "        dataset: IterationBuffer,\n",
    "    ) -> None:\n",
    "        \"\"\"Do gradient step.\n",
    "\n",
    "        Args:\n",
    "            objective (Callable[[torch.tensor], torch.tensor]): objective to optimize\n",
    "            dataset (Dataset): data for optmization\n",
    "        \"\"\"\n",
    "\n",
    "        dataloader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            shuffle=self.shuffle,\n",
    "            batch_size=len(dataset),\n",
    "        )\n",
    "        batch_sample = next(iter(dataloader))\n",
    "        self.optimizer.zero_grad()\n",
    "        objective_value = objective(batch_sample)\n",
    "        objective_value.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        last_observation = dataset.observations[-1]\n",
    "        if self.lr_scheduler_switch(last_observation) and self.lr_scheduler is not None:\n",
    "            self.lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyREINFORCE:\n",
    "    def __init__(\n",
    "        self, model: nn.Module, optimizer: Optimizer, device: str = \"cpu\", is_with_baseline: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize policy\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): model to optimize\n",
    "            optimizer (Optimizer): optimizer for `model` weights optimization\n",
    "            device (str, optional): device for gradient descent optimization procedure. Defaults to \"cpu\".\n",
    "            is_with_baseline (bool, optional): whether to use baseline in objective function.\n",
    "        \"\"\"\n",
    "\n",
    "        self.buffer = IterationBuffer()\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.is_with_baseline = is_with_baseline\n",
    "\n",
    "    def objective(self, batch: Dict[\"str\", torch.tensor]) -> torch.tensor:\n",
    "        \"\"\"This method computes a proxy objective specifically for automatic differentiation since its gradient is exactly as in REINFORCE\n",
    "\n",
    "        Args:\n",
    "            batch (torch.tensor): batch with catted observations-actions, total objectives and baselines\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: objective value\n",
    "        \"\"\"\n",
    "\n",
    "        observations_actions = batch[\"observations_actions\"].to(self.device)\n",
    "        tail_total_objectives = batch[\"tail_total_objectives\"].to(self.device)\n",
    "        baselines = batch[\"baselines\"].to(self.device)\n",
    "        N_episodes = self.N_episodes\n",
    "        #-----------------------------------------------------------------------\n",
    "        # HINT\n",
    "        # Return the surrogate objective value as described above\n",
    "        \n",
    "        # Get log probs of policy\n",
    "        log_probs = self.model.log_probs(observations_actions)\n",
    "        \n",
    "        return 1/N_episodes*((tail_total_objectives - baselines)*log_probs).sum()\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "\n",
    "    def REINFORCE_step(self) -> None:\n",
    "        \"\"\"Do gradient REINFORCE step\"\"\"\n",
    "\n",
    "        self.N_episodes = self.buffer.get_N_episodes()\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer.optimize(self.objective, self.buffer)\n",
    "        self.model.to(\"cpu\")\n",
    "        self.buffer.nullify_buffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulation Scenario (class for main loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloSimulationScenario:\n",
    "    \"\"\"Run whole REINFORCE procedure\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        simulator: Simulator,\n",
    "        system: HydraulicSystem,\n",
    "        policy: PolicyREINFORCE,\n",
    "        N_episodes: int,\n",
    "        N_iterations: int,\n",
    "        discount_factor: float = 1.0,\n",
    "        termination_criterion: Callable[\n",
    "            [np.array, np.array, float, float], bool\n",
    "        ] = lambda *args: False,\n",
    "    ):\n",
    "        \"\"\"Initialize scenario for main loop\n",
    "\n",
    "\n",
    "        Args:\n",
    "            simulator (Simulator): simulator for computing system dynamics\n",
    "            system (InvertedPendulumSystem): system itself\n",
    "            policy (PolicyREINFORCE): REINFORCE gradient stepper\n",
    "            N_episodes (int): number of episodes in one iteration\n",
    "            N_iterations (int): number of iterations\n",
    "            discount_factor (float, optional): discount factor for running objectives. Defaults to 1\n",
    "            termination_criterion (Callable[[np.array, np.array, float, float], bool], optional): criterion for episode termination. Takes observation, action, running_objective, total_objectove. Defaults to lambda*args:False\n",
    "        \"\"\"\n",
    "\n",
    "        self.simulator = simulator\n",
    "        self.system = system\n",
    "        self.policy = policy\n",
    "        self.N_episodes = N_episodes\n",
    "        self.N_iterations = N_iterations\n",
    "        self.termination_criterion = termination_criterion\n",
    "        self.discount_factor = discount_factor\n",
    "\n",
    "        self.total_objective = 0\n",
    "        self.total_objectives_episodic = []\n",
    "        self.learning_curve = []\n",
    "        self.last_observations = None\n",
    "\n",
    "    def compute_running_objective(\n",
    "        self, observation: np.array, action: np.array\n",
    "    ) -> float:\n",
    "        \"\"\"Computes running objective\n",
    "\n",
    "        Args:\n",
    "            observation (np.array): current observation\n",
    "            action (np.array): current action\n",
    "\n",
    "        Returns:\n",
    "            float: running objective value\n",
    "        \"\"\"\n",
    "        \n",
    "        length_diff = (1 - observation[0])\n",
    "        \n",
    "        # If length larger than critical, penalty for the positive velocity\n",
    "        # Velocity must be not positive\n",
    "        # if length_diff < 0:\n",
    "        #     velocity_objective = 1e4 * observation[1] * abs(observation[1])\n",
    "        # else:\n",
    "        #     velocity_objective = 0\n",
    "\n",
    "        # If length smaller than critical, penalty for the negative velocity\n",
    "        # If length larger than critical, penalty for the positive velocity\n",
    "        return length_diff ** 2 -\\\n",
    "            np.sign(length_diff) * observation[1] * abs(observation[1]) * 1e2\n",
    "\n",
    "    def run(self) -> None:\n",
    "        \"\"\"Run main loop\"\"\"\n",
    "\n",
    "        eps = 0.1\n",
    "        means_total_objectives = [eps]\n",
    "        for iteration_idx in range(self.N_iterations):\n",
    "            if iteration_idx % 10 == 0:\n",
    "                clear_output(wait=True)\n",
    "            for episode_idx in tqdm(range(self.N_episodes)):\n",
    "                terminated = False\n",
    "                while self.simulator.step():\n",
    "                    (\n",
    "                        step_idx,\n",
    "                        observation,\n",
    "                        action,\n",
    "                    ) = self.simulator.get_sim_step_data()\n",
    "\n",
    "                    new_action = (\n",
    "                        self.policy.model.sample(torch.tensor(observation).float())\n",
    "                        .detach()\n",
    "                        .cpu()\n",
    "                        .numpy()\n",
    "                    )\n",
    "                    discounted_running_objective = self.discount_factor ** (\n",
    "                        step_idx\n",
    "                    ) * self.compute_running_objective(observation, new_action)\n",
    "                    self.total_objective += discounted_running_objective\n",
    "\n",
    "                    if not terminated and self.termination_criterion(\n",
    "                        observation,\n",
    "                        new_action,\n",
    "                        discounted_running_objective,\n",
    "                        self.total_objective,\n",
    "                    ):\n",
    "                        terminated = True\n",
    "\n",
    "                    if not terminated:\n",
    "                        self.policy.buffer.add_step_data(\n",
    "                            np.copy(observation),\n",
    "                            np.copy(new_action),\n",
    "                            np.copy(discounted_running_objective),\n",
    "                            step_idx,\n",
    "                            episode_idx,\n",
    "                        )\n",
    "                    self.simulator.set_action(new_action)\n",
    "                self.simulator.reset()\n",
    "                self.total_objectives_episodic.append(self.total_objective)\n",
    "                self.total_objective = 0\n",
    "            self.learning_curve.append(np.mean(self.total_objectives_episodic))\n",
    "            self.last_observations = pd.DataFrame(\n",
    "                index=self.policy.buffer.episode_ids,\n",
    "                data=self.policy.buffer.observations.copy(),\n",
    "            )\n",
    "            self.last_actions = pd.DataFrame(\n",
    "                index=self.policy.buffer.episode_ids,\n",
    "                data=self.policy.buffer.actions.copy(),\n",
    "            )\n",
    "            self.policy.REINFORCE_step()\n",
    "\n",
    "            means_total_objectives.append(np.mean(self.total_objectives_episodic))\n",
    "            change = (means_total_objectives[-1] / means_total_objectives[-2] - 1) * 100\n",
    "            sign = \"-\" if np.sign(change) == -1 else \"+\"\n",
    "            print(\n",
    "                f\"Iteration: {iteration_idx + 1} / {self.N_iterations}, \"\n",
    "                + f\"mean total cost {round(means_total_objectives[-1], 2)}, \"\n",
    "                + f\"% change: {sign}{abs(round(change,2))}, \"\n",
    "                + f\"last observation: {self.last_observations.iloc[-1].values.reshape(-1)}\",\n",
    "                end=\"\\n\",\n",
    "            )\n",
    "\n",
    "            self.total_objectives_episodic = []\n",
    "\n",
    "    def plot_data(self):\n",
    "        \"\"\"Plot learning results\"\"\"\n",
    "\n",
    "        data = pd.Series(\n",
    "            index=range(1, len(self.learning_curve) + 1), data=self.learning_curve\n",
    "        )\n",
    "        na_mask = data.isna()\n",
    "        not_na_mask = ~na_mask\n",
    "        interpolated_values = data.interpolate()\n",
    "        interpolated_values[not_na_mask] = None\n",
    "        data.plot(marker=\"o\", markersize=3)\n",
    "        interpolated_values.plot(linestyle=\"--\")\n",
    "\n",
    "        plt.title(\"Total cost by iteration\")\n",
    "        plt.xlabel(\"Iteration number\")\n",
    "        plt.ylabel(\"Total cost\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.show()\n",
    "\n",
    "        ax_jet_length, ax_jet_velocity = pd.DataFrame(\n",
    "            data=self.last_observations.loc[0].values\n",
    "        ).plot(\n",
    "            xlabel=\"Step Number\",\n",
    "            title=\"Observations in last iteration\",\n",
    "            legend=False,\n",
    "            subplots=True,\n",
    "            grid=True,\n",
    "        )\n",
    "        ax_jet_length.set_ylabel(\"relative jet length\")\n",
    "        ax_jet_velocity.set_ylabel(\"relative jet velocity\")\n",
    "\n",
    "        ax_actions = pd.DataFrame(\n",
    "            data=self.last_actions.loc[0].values\n",
    "        ).plot(\n",
    "            xlabel=\"Step Number\",\n",
    "            title=\"Actions in last iteration\",\n",
    "            legend=False,\n",
    "            grid=True,\n",
    "        )\n",
    "        ax_actions.set_ylabel(\"action\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run simulation and fit REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 14\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "system = HydraulicSystem()\n",
    "## DO NOT CHANGE THE PARAMS OF SIMULATOR.\n",
    "simulator = Simulator(\n",
    "    system, N_steps=60, state_init=np.array([1e3, 0.0])\n",
    ")\n",
    "model = GaussianPDFModel(\n",
    "    dim_observation=system.dim_observation,\n",
    "    dim_action=system.dim_action,\n",
    "    action_bounds=np.array([[-40., 40]]), # These actions are expanded in comparison with real action\n",
    "    #---------------------------------------------------------------------------\n",
    "    # YOUR CODE GOES HERE\n",
    "    scale_factor=10.0,  # TRY TO FIND scale_factor EMPIRICALLY\n",
    "    dim_hidden=2, # TRY TO FIND dim_hidden EMPIRICALLY\n",
    "    std=0.02, # TRY TO FIND STD EMPIRICALLY\n",
    "    #---------------------------------------------------------------------------\n",
    ")\n",
    "\n",
    "optimizer = Optimizer(\n",
    "    model=model,\n",
    "    opt_method=torch.optim.Adam,\n",
    "    #---------------------------------------------------------------------------\n",
    "    # YOUR CODE GOES HERE\n",
    "    opt_options=dict(lr=1.0e-2), # TRY TO FIND lr EMPIRICALLY\n",
    "    #---------------------------------------------------------------------------\n",
    ")\n",
    "## Or if you want to use scheduler then initialize optimizer, via, for instance\n",
    "# lr_scheduler_fading_coeff = 1\n",
    "# optimizer = Optimizer(\n",
    "#     model=model,\n",
    "#     opt_method=torch.optim.Adam,\n",
    "#     opt_options=dict(lr=1.0, betas=(0.8, 0.9)),\n",
    "#     shuffle=False,\n",
    "#     lr_scheduler_method=torch.optim.lr_scheduler.MultiplicativeLR,\n",
    "#     lr_scheduler_options={\n",
    "#         \"lr_lambda\": lambda iteration: 1\n",
    "#         / np.sqrt((iteration / lr_scheduler_fading_coeff) ** 2 + 1)\n",
    "#     },\n",
    "#     lr_scheduler_switch=LRSchedulerSwitch(norm_observation_threshold=0.1),\n",
    "# )\n",
    "#\n",
    "# BELEIVE US! YOU CAN SOLVE THIS TASK WITHOUT SCHEDULER\n",
    "\n",
    "policy = PolicyREINFORCE(model, optimizer, is_with_baseline=True)\n",
    "\n",
    "\n",
    "# This termination criterion never terminates episodes\n",
    "trivial_terminantion_criterion = lambda *args: False\n",
    "\n",
    "## EXAMPLE. This termination criterion terminates episode if observation norm >= 20\n",
    "#\n",
    "# termination_criterion = (\n",
    "#     lambda observation, action, running_objective, total_objective: (\n",
    "#         np.linalg.norm(observation) >= 20\n",
    "#     )\n",
    "# )\n",
    "#\n",
    "# DO NOT USE TERMINATION CRITERION OTHER THAN trivial_termination_criterion\n",
    "\n",
    "\n",
    "scenario = MonteCarloSimulationScenario(\n",
    "    simulator=simulator,\n",
    "    system=system,\n",
    "    policy=policy,\n",
    "    #---------------------------------------------------------------------------\n",
    "    # YOUR CODE GOES HERE\n",
    "    N_episodes=2, # Increasing the number of episodes stabilizes learning, but you can manage it with N_episodes=1\n",
    "    N_iterations=200, # You can change the number of iterations if you want\n",
    "    #---------------------------------------------------------------------------\n",
    "    termination_criterion=trivial_terminantion_criterion,\n",
    "    discount_factor=1.0, # do not change this\n",
    ")\n",
    "\n",
    "try:\n",
    "    scenario.run()\n",
    "except KeyboardInterrupt:\n",
    "    clear_output(wait=True)\n",
    "    scenario.plot_data()\n",
    "\n",
    "clear_output(wait=True)\n",
    "scenario.plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    scenario.run()\n",
    "except KeyboardInterrupt:\n",
    "    clear_output(wait=True)\n",
    "    scenario.plot_data()\n",
    "\n",
    "clear_output(wait=True)\n",
    "scenario.plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD State dynamics function\n",
    "\n",
    "State dynamics function is:\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        &   \\dot{x_p} = \\begin{cases} v_p, \\text{ if } [x_{th} > 0] \\text{ and } [F_h(v_p, x_{th}) > |F_{fr}(v_p, x_{th})|] \\\\\n",
    "                        0, \\text{ otherwise }\\end{cases}\n",
    "        \\\\\n",
    "        &   \\dot{v_p} = \\begin{cases} \\frac{1}{m_p}[F_h(v_p, x_{th}) + F_{fr}(v_p, x_{th})], \\text{ if } [x_{th} > 0] \\text{ and } [F_h(v_p, x_{th}) > |F_{fr}(v_p, x_{th})|] \\\\\n",
    "                        0, \\text{ otherwise }\\end{cases}\n",
    "    \\end{aligned}\n",
    "    \\qquad x_{th} \\in [0, x_{th}^{max}],\n",
    "$$\n",
    "\n",
    "where (if $x_{th}>0$):\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "        &   F_h(v_p, x_{th}) = \\left[p_l - \\frac{\\zeta_{th}\\rho_h D_h^4}{32D_{th}^2}\\left(\\frac{v_p}{x_{th}}\\right)^2 \\right]A_h - \\left[p_{atm} + \\frac{\\zeta_{exit}\\rho_t D_t^4}{2D_{exit}^4}v_p^2 \\right]A_t, \\\\\n",
    "        &   F_{fr}(v_p, x_{th}) = -\\frac{v_p}{|v_p|}\\max{[p_C\\cdot A_{max}, (1-\\eta)\\cdot F_h(v_p, x_{th})]}. \\\\\n",
    "    \\end{aligned}\n",
    "$$\n",
    "\n",
    "where $A_{max} = \\max{(A_h, A_t)}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
