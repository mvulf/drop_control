# Droplet Generator optimal control
The **goal** of this project is to create an optimal control of the droplet generator (it's hydraulic part) by Reinforcement Learning.

## Content
- Current main notebook with a detailed description of the Droplet Generation System is introduced in the root of the repository ([reinforce_hydraulic_system.ipynb](https://github.com/mvulf/drop_control/blob/main/reinforce_hydraulic_system.ipynb))
- Conducted research is introduced in the [research](https://github.com/mvulf/drop_control/tree/main/research) folder:
    - Searching of the **best running cost** function is introduced in the notebooks [reinforce_jet_length_penalty.ipynb](https://github.com/mvulf/drop_control/blob/main/research/reinforce_jet_length_penalty.ipynb), [reinforce_pos_vel_penalty.ipynb](https://github.com/mvulf/drop_control/blob/main/research/reinforce_pos_vel_penalty.ipynb), and [reinforce_vel_reward_and_penalty.ipynb](https://github.com/mvulf/drop_control/blob/main/research/reinforce_vel_reward_and_penalty.ipynb). 
    - Next two notebooks ([reinforce_vel_reward_and_penalty_continue.ipynb](https://github.com/mvulf/drop_control/blob/main/research/reinforce_vel_reward_and_penalty_continue.ipynb), [reinforce_vel_reward_and_penalty_continue_2.ipynb](https://github.com/mvulf/drop_control/blob/main/research/reinforce_vel_reward_and_penalty_continue_2.ipynb)) were used to continue weights updating and to save obtained models as [model_policy_reinforce_updated(_2).ipynb](https://github.com/mvulf/drop_control/tree/main/data). It was necessary to separate solution, since some freezing happends due to the solve_ivp: it takes a lot of time to calculate states when throttle position near the 0.
    - Next two 